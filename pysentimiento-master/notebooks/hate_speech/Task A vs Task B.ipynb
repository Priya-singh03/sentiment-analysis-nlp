{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-combi.json\t\t\t  beto_pred.json\n",
      "bert-hier.json\t\t\t  roberta-combi.json\n",
      "bert.json\t\t\t  roberta-hier.json\n",
      "bertweet-combi.json\t\t  roberta.json\n",
      "bertweet-hier.json\t\t  robertuito-combi.json\n",
      "bertweet.json\t\t\t  robertuito-hierarchical-gamma-0.1.json\n",
      "beto-combi.json\t\t\t  robertuito-hierarchical-gamma-0.json\n",
      "beto-hierarchical-gamma-0.1.json  robertuito.json\n",
      "beto-hierarchical-gamma-0.json\t  robertuito_pred.json\n",
      "beto.json\n"
     ]
    }
   ],
   "source": [
    "!ls ../../evaluations/hate_speech/task_b/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "evaluations = {\n",
    "\n",
    "}\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "runs = {\n",
    "\n",
    "}\n",
    "\n",
    "for model_name, path in [\n",
    "    ('beto-a', '../../evaluations/hate_speech/task_a/beto.json'),\n",
    "    ('beto-b', '../../evaluations/hate_speech/task_b/beto.json'),\n",
    "    ('bertweet-a', '../../evaluations/hate_speech/task_a/bertweet.json'),\n",
    "    ('bertweet-b', '../../evaluations/hate_speech/task_b/bertweet.json'),\n",
    "    ]:\n",
    "    with open(path) as f:\n",
    "        runs[model_name] = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for a_model in [\"beto-a\", \"bertweet-a\"]:\n",
    "    for run in runs[a_model][\"evaluations\"][\"hate_speech\"]:\n",
    "        data.append({\n",
    "            \"model\": a_model,\n",
    "            \"precision\": run[\"eval_hateful_precision\"],\n",
    "            \"recall\": run[\"eval_hateful_recall\"],\n",
    "            \"f1\": run[\"eval_hateful_f1\"],\n",
    "            \"macro_f1\": run[\"eval_macro_f1\"],\n",
    "        })\n",
    "\n",
    "for b_model in [\"beto-b\", \"bertweet-b\"]:\n",
    "    for run in runs[b_model][\"evaluations\"][\"hate_speech\"]:\n",
    "        data.append({\n",
    "            \"model\": b_model,\n",
    "            \"precision\": run[\"eval_hs_precision\"],\n",
    "            \"recall\": run[\"eval_hs_recall\"],\n",
    "            \"f1\": run[\"eval_hs_f1\"],\n",
    "            \"macro_f1\": run[\"eval_macro_hs_f1_score\"],\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "{} &       precision &          recall &              f1 &        macro\\_f1 \\\\\n",
      "model      &                 &                 &                 &                 \\\\\n",
      "\\midrule\n",
      "bertweet-a &  0.495 +- 0.012 &  0.959 +- 0.012 &  0.653 +- 0.009 &  0.546 +- 0.027 \\\\\n",
      "bertweet-b &  0.505 +- 0.011 &  0.948 +- 0.018 &  0.658 +- 0.005 &  0.567 +- 0.022 \\\\\n",
      "beto-a     &  0.674 +- 0.021 &  0.839 +- 0.026 &  0.747 +- 0.007 &  0.764 +- 0.011 \\\\\n",
      "beto-b     &  0.713 +- 0.042 &  0.778 +- 0.054 &  0.741 +- 0.013 &  0.771 +- 0.015 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby([\"model\"])\n",
    "show_df = grouped.mean().round(3).astype(str) + \" +- \" + grouped.std().round(3).astype(str)\n",
    "\n",
    "print(show_df.to_latex())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=0.6509018036072056, pvalue=0.7222016381935228)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.kruskal(standard[\"emr\"], hier[\"emr\"], combi[\"emr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=3.6567741935483866, pvalue=0.16067250810281022)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.kruskal(standard[\"f1\"], hier[\"f1\"], combi[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=26.5, pvalue=0.08186862373064437)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.mannwhitneyu(standard[\"emr\"], hier[\"emr\"], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No lo es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=10.860138146167559, pvalue=0.004382793059181017)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "combi_emr = [evaluation[\"eval_emr\"] for evaluation in evaluations[\"robertuito-combi\"][\"evaluations\"][\"hate_speech\"]]\n",
    "hier_emr = [evaluation[\"eval_emr\"] for evaluation in evaluations[\"robertuito-hier\"][\"evaluations\"][\"hate_speech\"]]\n",
    "standard_emr = [evaluation[\"eval_emr\"] for evaluation in evaluations[\"robertuito\"][\"evaluations\"][\"hate_speech\"]]\n",
    "\n",
    "scipy.stats.kruskal(standard_emr, hier_emr, combi_emr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de robertuito s√≠! wtf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "387abc9bc94d8eb1bd0148a5d4cb2bf99bc3b40fa501b808e2b508b4f65ed831"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('pysentimiento-bwlKzHxB-py3.7': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
