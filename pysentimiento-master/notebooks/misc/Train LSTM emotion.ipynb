{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LSTM model\n",
    "\n",
    "In this notebook we will train a LSTM model for Sentiment Analysis in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset, Value, ClassLabel, Features\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "from pysentimiento.emotion import load_datasets\n",
    "\n",
    "\n",
    "train_dataset, dev_dataset, test_dataset = load_datasets(preprocessing_args={\n",
    "    \"user_token\": \"USUARIO\",\n",
    "    \"url_token\": \"URL\",\n",
    "    \"hashtag_token\": \"hashtag\",\n",
    "    \"emoji_wrapper\": \"\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0, 1, 2, 3, 4, 5, 6] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pysentimiento.emotion import id2label\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weight = torch.Tensor(\n",
    "    compute_class_weight('balanced', list(id2label), y=train_dataset[\"label\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16313"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "import unidecode\n",
    "\n",
    "tokenizer = get_tokenizer(\"spacy\", \"es_core_news_sm\")\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "\"\"\"\n",
    "No overfitting, just taking the embeddings\n",
    "\"\"\"\n",
    "for dataset in [train_dataset, dev_dataset, test_dataset]:\n",
    "    for example in dataset:\n",
    "        tokens = tokenizer(unidecode.unidecode(example[\"text\"].lower()))\n",
    "        counter.update(tokens)\n",
    "\n",
    "# Meto todas\n",
    "vocab = Vocab(counter, min_freq=1)\n",
    "\n",
    "len(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262fd527d2634487899d8d2125d58ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5049.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e7f18daf24470ab8b28258ed211e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1683.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c308be48bbe4d6c8def3474cd9b1f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1677.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tokenize(batch):\n",
    "    text = unidecode.unidecode(batch['text'].lower())\n",
    "    tokens = tokenizer(text)\n",
    "    token_ids = [vocab.stoi[t] for t in tokens]\n",
    "    return {\"input_ids\": token_ids}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "eval_batch_size = 16\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=False)\n",
    "dev_dataset = dev_dataset.map(tokenize, batched=False)\n",
    "test_dataset = test_dataset.map(tokenize, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645a2b05ac2e4d588317aff45f57cb75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5049.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b676a591fe68469fb6d148c70a494b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1683.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a7556d13e04e02922a3553cbdf7809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1677.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def format_dataset(dataset):\n",
    "    dataset = dataset.map(lambda examples: {'labels': examples['label']})\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'labels'])\n",
    "    return dataset\n",
    "\n",
    "train_dataset = format_dataset(train_dataset)\n",
    "dev_dataset = format_dataset(dev_dataset)\n",
    "test_dataset = format_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import fasttext\n",
    "\n",
    "fasttext_model = fasttext.load_model(\"../../embeddings/cc.es.300.bin\")\n",
    "\n",
    "\n",
    "DIM = fasttext_model.get_word_vector(\"random\").shape[0]\n",
    "emb_matrix = torch.randn(len(vocab), DIM)\n",
    "UNK_IDX = vocab.stoi[\"<unk>\"]\n",
    "PAD_IDX = vocab.stoi[\"<pad>\"]\n",
    "\n",
    "# emb_matrix[UNK_IDX] = 0\n",
    "emb_matrix[PAD_IDX] = 0\n",
    "\n",
    "for i, word in enumerate(vocab.itos):\n",
    "    if i == UNK_IDX or i == PAD_IDX:\n",
    "        # Let them unmodified\n",
    "        pass\n",
    "    else:\n",
    "        emb_matrix[i] = torch.tensor(fasttext_model.get_word_vector(word))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "PAD_IDX = vocab.stoi[\"<pad>\"]\n",
    "\n",
    "def collate_batch(batch):\n",
    "    labels = [t[\"labels\"] for t in batch]\n",
    "    input_ids = [t[\"input_ids\"] for t in batch]\n",
    "\n",
    "    # Return text, text_lens, labels\n",
    "    return pad_sequence(input_ids, padding_value=PAD_IDX, batch_first=True), torch.tensor([len(t) for t in input_ids]), torch.tensor(labels)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_batch)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=16, collate_fn=collate_batch)\n",
    "test_dataset = DataLoader(test_dataset, batch_size=16, collate_fn=collate_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from pysentimiento.emotion import id2label\n",
    "from pysentimiento.metrics import get_metrics\n",
    "from torch import nn\n",
    "\n",
    "class RNNModel(pl.LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dim, pad_idx, rnn_units, num_labels, num_layers=1,\n",
    "                 bidirectional=False, dropout=0.25, embedding_matrix=None, freeze_embeddings=True):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                embedding_matrix, padding_idx=pad_idx,\n",
    "                freeze=freeze_embeddings\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(\n",
    "                vocab_size, embedding_dim,\n",
    "                padding_idx = pad_idx)\n",
    "\n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                   rnn_units,\n",
    "                   num_layers=num_layers,\n",
    "                   bidirectional=bidirectional, batch_first=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        factor = 2 if bidirectional else 1\n",
    "\n",
    "        self.fc = nn.Linear(rnn_units * factor, num_labels)\n",
    "\n",
    "    def forward(self, text, text_lens):\n",
    "        #text = [batch_size, text len]\n",
    "        #permuted = text.permute(1, 0)\n",
    "        # permuted shape [batch_size, sent len]\n",
    "        embedded = self.embedding(text)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(\n",
    "            # WTF no sé por qué hago esto de cpu\n",
    "            embedded, text_lens.to(\"cpu\"), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        packed_output, _ = self.rnn(packed_embedded)\n",
    "        # hidden is the last state of the\n",
    "\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        # output is shape [seq, batch, hid]\n",
    "        s = output.permute(1, 0, 2)\n",
    "        # now [batch, seq, hid]\n",
    "        mean = s.sum(dim=1) / text_lens.view(-1, 1)\n",
    "\n",
    "        return self.fc(mean)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, lens, y = batch\n",
    "        outs = self.forward(x, lens)\n",
    "        loss = F.cross_entropy(outs, y, weight=class_weight.to(x.device))\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, lens, y = batch\n",
    "        outs = self.forward(x, lens)\n",
    "        loss = F.cross_entropy(outs, y, weight=class_weight.to(x.device))\n",
    "        preds = outs.argmax(-1).cpu()\n",
    "        metrics = get_metrics(preds, y.cpu(), id2label)\n",
    "        self.log('val_loss', loss, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        for k, v in metrics.items():\n",
    "            self.log(\"val_\"+k, v, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, lens, y = batch\n",
    "        outs = self.forward(x, lens)\n",
    "        preds = outs.argmax(-1).cpu()\n",
    "        metrics = get_metrics(preds, y.cpu(), id2label)\n",
    "\n",
    "        for k, v in metrics.items():\n",
    "            self.log(\"test_\"+k, v, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | embedding | Embedding | 4.9 M \n",
      "1 | rnn       | GRU       | 428 K \n",
      "2 | dropout   | Dropout   | 0     \n",
      "3 | fc        | Linear    | 1.8 K \n",
      "----------------------------------------\n",
      "430 K     Trainable params\n",
      "4.9 M     Non-trainable params\n",
      "5.3 M     Total params\n",
      "21.297    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282c04d5d2af451bb9048ecff6edde3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406cf915814f44058ecb4c0798962578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e9c3cb13fd44fab5a0cb5ed3ab1281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:610: LightningDeprecationWarning: Relying on `self.log('val_loss', ...)` to set the ModelCheckpoint monitor is deprecated in v1.2 and will be removed in v1.4. Please, create your own `mc = ModelCheckpoint(monitor='your_monitor')` and use it as `Trainer(callbacks=[mc])`.\n",
      "  warning_cache.deprecation(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57628d8874f440b2ae763cd7c6a363df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c602c652689a461a8d55f87f778be74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6bb7fbd1a543c9817c0f406f8c5d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccdab47a9844c72bd5292c657a6b92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = RNNModel(\n",
    "    vocab_size=len(vocab), embedding_dim=DIM, pad_idx=PAD_IDX, rnn_units=256, embedding_matrix=emb_matrix,\n",
    "    freeze_embeddings=True, num_labels=7,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5, \n",
    "    gpus=1\n",
    ")\n",
    "trainer.fit(model, train_dataloader, dev_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1806e349f84a8b961ce679e8565588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.5211687684059143,\n",
      " 'test_anger_f1': 0.16684989631175995,\n",
      " 'test_anger_precision': 0.1739974021911621,\n",
      " 'test_anger_recall': 0.21719539165496826,\n",
      " 'test_disgust_f1': 0.052338361740112305,\n",
      " 'test_disgust_precision': 0.04770423471927643,\n",
      " 'test_disgust_recall': 0.07791692018508911,\n",
      " 'test_fear_f1': 0.051096536219120026,\n",
      " 'test_fear_precision': 0.040548600256443024,\n",
      " 'test_fear_recall': 0.08109720051288605,\n",
      " 'test_joy_f1': 0.4242527186870575,\n",
      " 'test_joy_precision': 0.4065885543823242,\n",
      " 'test_joy_recall': 0.4828502833843231,\n",
      " 'test_macro_f1': 0.20564809441566467,\n",
      " 'test_macro_precision': 0.23136986792087555,\n",
      " 'test_macro_recall': 0.2187984585762024,\n",
      " 'test_micro_f1': 0.5211687684059143,\n",
      " 'test_others_f1': 0.517051637172699,\n",
      " 'test_others_precision': 0.6873546242713928,\n",
      " 'test_others_recall': 0.44072675704956055,\n",
      " 'test_sadness_f1': 0.15013666450977325,\n",
      " 'test_sadness_precision': 0.1970866322517395,\n",
      " 'test_sadness_recall': 0.13051065802574158,\n",
      " 'test_surprise_f1': 0.07781090587377548,\n",
      " 'test_surprise_precision': 0.0663088858127594,\n",
      " 'test_surprise_recall': 0.10129199177026749}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_others_f1': 0.517051637172699,\n",
       "  'test_others_precision': 0.6873546242713928,\n",
       "  'test_others_recall': 0.44072675704956055,\n",
       "  'test_joy_f1': 0.4242527186870575,\n",
       "  'test_joy_precision': 0.4065885543823242,\n",
       "  'test_joy_recall': 0.4828502833843231,\n",
       "  'test_sadness_f1': 0.15013666450977325,\n",
       "  'test_sadness_precision': 0.1970866322517395,\n",
       "  'test_sadness_recall': 0.13051065802574158,\n",
       "  'test_anger_f1': 0.16684989631175995,\n",
       "  'test_anger_precision': 0.1739974021911621,\n",
       "  'test_anger_recall': 0.21719539165496826,\n",
       "  'test_surprise_f1': 0.07781090587377548,\n",
       "  'test_surprise_precision': 0.0663088858127594,\n",
       "  'test_surprise_recall': 0.10129199177026749,\n",
       "  'test_disgust_f1': 0.052338361740112305,\n",
       "  'test_disgust_precision': 0.04770423471927643,\n",
       "  'test_disgust_recall': 0.07791692018508911,\n",
       "  'test_fear_f1': 0.051096536219120026,\n",
       "  'test_fear_precision': 0.040548600256443024,\n",
       "  'test_fear_recall': 0.08109720051288605,\n",
       "  'test_micro_f1': 0.5211687684059143,\n",
       "  'test_macro_f1': 0.20564809441566467,\n",
       "  'test_macro_precision': 0.23136986792087555,\n",
       "  'test_macro_recall': 0.2187984585762024,\n",
       "  'test_acc': 0.5211687684059143}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import fasttext\n",
    "\n",
    "fasttext_model = fasttext.load_model(\"../../embeddings/tweet_dim_300_ws_5.bin\")\n",
    "\n",
    "\n",
    "DIM = fasttext_model.get_word_vector(\"random\").shape[0]\n",
    "emb_matrix = torch.randn(len(vocab), DIM)\n",
    "UNK_IDX = vocab.stoi[\"<unk>\"]\n",
    "PAD_IDX = vocab.stoi[\"<pad>\"]\n",
    "\n",
    "# emb_matrix[UNK_IDX] = 0\n",
    "emb_matrix[PAD_IDX] = 0\n",
    "\n",
    "for i, word in enumerate(vocab.itos):\n",
    "    if i == UNK_IDX or i == PAD_IDX:\n",
    "        # Let them unmodified\n",
    "        pass\n",
    "    else:\n",
    "        emb_matrix[i] = torch.tensor(fasttext_model.get_word_vector(word))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | embedding | Embedding | 4.9 M \n",
      "1 | rnn       | GRU       | 428 K \n",
      "2 | dropout   | Dropout   | 0     \n",
      "3 | fc        | Linear    | 1.8 K \n",
      "----------------------------------------\n",
      "430 K     Trainable params\n",
      "4.9 M     Non-trainable params\n",
      "5.3 M     Total params\n",
      "21.297    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9cc5ddde9f462184317e52f84272fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90f791fd67744e7a0e4118f5e05c12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56cd8d689f184648a427b1b42e50c819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1e94e5081247308b2861e65f97dc5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71fd24b76d3b4dd894f8030bc478086e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cbb0db8cdc4463ac35c742ba867ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd2f8146320454ca3eb92a75c57d1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(\n",
    "    vocab_size=len(vocab), embedding_dim=DIM, pad_idx=PAD_IDX, rnn_units=256, embedding_matrix=emb_matrix,\n",
    "    freeze_embeddings=True, num_labels=7,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5, \n",
    "    gpus=1\n",
    ")\n",
    "trainer.fit(model, train_dataloader, dev_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98b883c338a4cf29e275f4834fe4d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.5557543039321899,\n",
      " 'test_anger_f1': 0.19131353497505188,\n",
      " 'test_anger_precision': 0.1866428107023239,\n",
      " 'test_anger_recall': 0.22623974084854126,\n",
      " 'test_disgust_f1': 0.04770423471927643,\n",
      " 'test_disgust_precision': 0.04531902074813843,\n",
      " 'test_disgust_recall': 0.05485986918210983,\n",
      " 'test_fear_f1': 0.04727261886000633,\n",
      " 'test_fear_precision': 0.0367322601377964,\n",
      " 'test_fear_recall': 0.08348240703344345,\n",
      " 'test_joy_f1': 0.45676466822624207,\n",
      " 'test_joy_precision': 0.4410092532634735,\n",
      " 'test_joy_recall': 0.5313382148742676,\n",
      " 'test_macro_f1': 0.22454555332660675,\n",
      " 'test_macro_precision': 0.24968823790550232,\n",
      " 'test_macro_recall': 0.24108773469924927,\n",
      " 'test_micro_f1': 0.5557543039321899,\n",
      " 'test_others_f1': 0.48737478256225586,\n",
      " 'test_others_precision': 0.7017671465873718,\n",
      " 'test_others_recall': 0.3992690145969391,\n",
      " 'test_sadness_f1': 0.2416417896747589,\n",
      " 'test_sadness_precision': 0.25631389021873474,\n",
      " 'test_sadness_recall': 0.2392943948507309,\n",
      " 'test_surprise_f1': 0.09974727779626846,\n",
      " 'test_surprise_precision': 0.0800333246588707,\n",
      " 'test_surprise_recall': 0.15313057601451874}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_others_f1': 0.48737478256225586,\n",
       "  'test_others_precision': 0.7017671465873718,\n",
       "  'test_others_recall': 0.3992690145969391,\n",
       "  'test_joy_f1': 0.45676466822624207,\n",
       "  'test_joy_precision': 0.4410092532634735,\n",
       "  'test_joy_recall': 0.5313382148742676,\n",
       "  'test_sadness_f1': 0.2416417896747589,\n",
       "  'test_sadness_precision': 0.25631389021873474,\n",
       "  'test_sadness_recall': 0.2392943948507309,\n",
       "  'test_anger_f1': 0.19131353497505188,\n",
       "  'test_anger_precision': 0.1866428107023239,\n",
       "  'test_anger_recall': 0.22623974084854126,\n",
       "  'test_surprise_f1': 0.09974727779626846,\n",
       "  'test_surprise_precision': 0.0800333246588707,\n",
       "  'test_surprise_recall': 0.15313057601451874,\n",
       "  'test_disgust_f1': 0.04770423471927643,\n",
       "  'test_disgust_precision': 0.04531902074813843,\n",
       "  'test_disgust_recall': 0.05485986918210983,\n",
       "  'test_fear_f1': 0.04727261886000633,\n",
       "  'test_fear_precision': 0.0367322601377964,\n",
       "  'test_fear_recall': 0.08348240703344345,\n",
       "  'test_micro_f1': 0.5557543039321899,\n",
       "  'test_macro_f1': 0.22454555332660675,\n",
       "  'test_macro_precision': 0.24968823790550232,\n",
       "  'test_macro_recall': 0.24108773469924927,\n",
       "  'test_acc': 0.5557543039321899}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1b2ee3c7e4be117f16044e4287774c113d04cbc1cc9e7e3b16e6e098f73486a4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('pysent-oyXQVI9B': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "1b2ee3c7e4be117f16044e4287774c113d04cbc1cc9e7e3b16e6e098f73486a4"
   }
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}